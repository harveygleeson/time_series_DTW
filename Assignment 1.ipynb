{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a224e7ac",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc93050",
   "metadata": {},
   "source": [
    "## Imports\n",
    "All necessary imports below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f7e5ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import unittest\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d10993",
   "metadata": {},
   "source": [
    "## Task 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e964ac",
   "metadata": {},
   "source": [
    "### Implement a 1-NN Classifier for Time-Series Data\n",
    "Here I create a 1-NN Classifier for the time-series data, with fit, predict and scoring methods that behave similarly to sklearn implementations. I use the dtw function provided to calculate distances between time series arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "165990d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTWOneNNClassifier():\n",
    "    \n",
    "    # DTW Function\n",
    "    def dtw(self, s, t, window):\n",
    "        n, m = len(s), len(t)\n",
    "        w = np.max([window, abs(n-m)]) # warping cannot be less than the difference in lengths. \n",
    "        dtw_matrix = np.zeros((n+1, m+1))\n",
    "\n",
    "        for i in range(n+1):\n",
    "            for j in range(m+1):\n",
    "                dtw_matrix[i, j] = np.inf\n",
    "        dtw_matrix[0, 0] = 0\n",
    "\n",
    "        for i in range(1, n+1):\n",
    "            for j in range(np.max([1, i-w]), np.min([m, i+w])+1):\n",
    "                dtw_matrix[i, j] = 0\n",
    "\n",
    "        for i in range(1, n+1):\n",
    "            for j in range(np.max([1, i-w]), np.min([m, i+w])+1):\n",
    "                cost = abs(s[i-1] - t[j-1])\n",
    "                # take last min from a square box\n",
    "                last_min = np.min([dtw_matrix[i-1, j], dtw_matrix[i, j-1], dtw_matrix[i-1, j-1]])\n",
    "                dtw_matrix[i, j] = cost + last_min\n",
    "        return dtw_matrix[-1,-1]\n",
    "\n",
    "    # Fit the training and target data\n",
    "    def fit(self, train, targets):\n",
    "        self.train = train\n",
    "        self.targets = targets\n",
    "        return self\n",
    "    \n",
    "    # Determine nearest value based off input, default window size is 3\n",
    "    def predict(self, array_of_times, window=3):\n",
    "        \n",
    "        # Set minimum distance to inf\n",
    "        min_dist = np.inf\n",
    "\n",
    "        # Loop through training set\n",
    "        for i in range(len(self.train)):\n",
    "            \n",
    "            # Determine distance between input times and training set \n",
    "            dist = self.dtw(array_of_times, self.train[i], window)\n",
    "\n",
    "            # If distance is lower than min, update min and get index\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                target = i\n",
    "            \n",
    "        return self.targets[target]  \n",
    "    \n",
    "    # Determine the accuracy score\n",
    "    def score(self, test_features, test_targets, window=3):\n",
    "        \n",
    "        # Score as a percentage of total\n",
    "        total = len(test_features)\n",
    "        hits = 0\n",
    "\n",
    "        # For each test feature, check if correct or not\n",
    "        for i in range(len(test_features)):\n",
    "            if self.predict(test_features[i], window) == test_targets[i]:\n",
    "                hits += 1\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        return hits / total\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7913e73",
   "metadata": {},
   "source": [
    "### Test with sample data\n",
    "Below I implement some tests on the classifier to see if it works as I expect, the tests include using two small arrays with easy to interpret values, distances and classes, and ensuring the expected classes are predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c9ab7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_with_dummy_data_1 (__main__.TestClassifier) ... ok\n",
      "test_with_dummy_data_2 (__main__.TestClassifier) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.024s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f7c598ab700>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestClassifier(unittest.TestCase):\n",
    "    \n",
    "    def test_with_dummy_data_1(self):\n",
    "        t = DTWOneNNClassifier()\n",
    "        t = t.fit([[1,1,1],[2,2,2]], [\"Class 1\", \"Class 2\"] )\n",
    "        res = t.predict([1,1,1])\n",
    "        self.assertEqual(\"Class 1\", res)\n",
    "        \n",
    "    def test_with_dummy_data_2(self):\n",
    "        t = DTWOneNNClassifier()\n",
    "        t = t.fit([[1,1,1],[2,2,2]], [\"Class 1\", \"Class 2\"] )\n",
    "        res = t.predict([2,2,2])\n",
    "        self.assertEqual(\"Class 2\", res)\n",
    "        \n",
    "unittest.main(argv=[''], verbosity=2, exit=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03aba39",
   "metadata": {},
   "source": [
    "# Task 1.2 Test Classifier Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd79588",
   "metadata": {},
   "source": [
    "### Using the UMD Data\n",
    "Below I read in the UMD data and isolate the target and feature values. Then I divide the dataset into a training and testing split. I use the training sets to train the classifier, and then work out the accuracy of the classifier using the unseen test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10f9eda6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7_/wlwr4q_96fl6zfdnq30n7gmc0000gp/T/ipykernel_24230/1317055495.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  UMD = pd.read_csv('UMD_TEST.txt', delimiter=\"  \", header=None)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017644</td>\n",
       "      <td>0.030949</td>\n",
       "      <td>0.050555</td>\n",
       "      <td>0.044484</td>\n",
       "      <td>0.053277</td>\n",
       "      <td>0.041576</td>\n",
       "      <td>0.030947</td>\n",
       "      <td>0.027086</td>\n",
       "      <td>0.013764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024575</td>\n",
       "      <td>0.033780</td>\n",
       "      <td>0.026589</td>\n",
       "      <td>0.013932</td>\n",
       "      <td>0.024928</td>\n",
       "      <td>0.022589</td>\n",
       "      <td>0.038248</td>\n",
       "      <td>0.049838</td>\n",
       "      <td>0.053419</td>\n",
       "      <td>0.040420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.041296</td>\n",
       "      <td>0.003551</td>\n",
       "      <td>0.027470</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.009571</td>\n",
       "      <td>0.008074</td>\n",
       "      <td>0.043743</td>\n",
       "      <td>0.040592</td>\n",
       "      <td>0.012190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060539</td>\n",
       "      <td>0.046991</td>\n",
       "      <td>0.023586</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>-0.002196</td>\n",
       "      <td>0.036730</td>\n",
       "      <td>0.039027</td>\n",
       "      <td>0.007754</td>\n",
       "      <td>0.004697</td>\n",
       "      <td>0.031440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000720</td>\n",
       "      <td>0.013283</td>\n",
       "      <td>0.029450</td>\n",
       "      <td>0.045201</td>\n",
       "      <td>0.006317</td>\n",
       "      <td>0.018805</td>\n",
       "      <td>0.028901</td>\n",
       "      <td>0.013832</td>\n",
       "      <td>0.015240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016442</td>\n",
       "      <td>0.039508</td>\n",
       "      <td>0.015171</td>\n",
       "      <td>0.034708</td>\n",
       "      <td>0.010835</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.006924</td>\n",
       "      <td>0.029502</td>\n",
       "      <td>0.040786</td>\n",
       "      <td>0.023144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.013363</td>\n",
       "      <td>0.025733</td>\n",
       "      <td>0.026653</td>\n",
       "      <td>0.038946</td>\n",
       "      <td>0.012494</td>\n",
       "      <td>0.028303</td>\n",
       "      <td>0.032011</td>\n",
       "      <td>0.009467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006383</td>\n",
       "      <td>0.037448</td>\n",
       "      <td>0.044335</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>-0.003624</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.020991</td>\n",
       "      <td>0.027675</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.015858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.022926</td>\n",
       "      <td>0.027036</td>\n",
       "      <td>0.011668</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.036049</td>\n",
       "      <td>-0.001297</td>\n",
       "      <td>0.019717</td>\n",
       "      <td>0.039583</td>\n",
       "      <td>0.020628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026997</td>\n",
       "      <td>0.036653</td>\n",
       "      <td>0.018117</td>\n",
       "      <td>0.018314</td>\n",
       "      <td>0.012536</td>\n",
       "      <td>0.040599</td>\n",
       "      <td>0.016590</td>\n",
       "      <td>0.032730</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>0.011260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1         2         3         4         5         6         7    \\\n",
       "0  1.0  0.017644  0.030949  0.050555  0.044484  0.053277  0.041576  0.030947   \n",
       "1  1.0  0.041296  0.003551  0.027470  0.013158  0.009571  0.008074  0.043743   \n",
       "2  1.0 -0.000720  0.013283  0.029450  0.045201  0.006317  0.018805  0.028901   \n",
       "3  1.0  0.005201  0.013363  0.025733  0.026653  0.038946  0.012494  0.028303   \n",
       "4  1.0  0.022926  0.027036  0.011668  0.019500  0.036049 -0.001297  0.019717   \n",
       "\n",
       "        8         9    ...       141       142       143       144       145  \\\n",
       "0  0.027086  0.013764  ...  0.024575  0.033780  0.026589  0.013932  0.024928   \n",
       "1  0.040592  0.012190  ...  0.060539  0.046991  0.023586  0.001562 -0.002196   \n",
       "2  0.013832  0.015240  ...  0.016442  0.039508  0.015171  0.034708  0.010835   \n",
       "3  0.032011  0.009467  ...  0.006383  0.037448  0.044335  0.011143 -0.003624   \n",
       "4  0.039583  0.020628  ...  0.026997  0.036653  0.018117  0.018314  0.012536   \n",
       "\n",
       "        146       147       148       149       150  \n",
       "0  0.022589  0.038248  0.049838  0.053419  0.040420  \n",
       "1  0.036730  0.039027  0.007754  0.004697  0.031440  \n",
       "2  0.002942  0.006924  0.029502  0.040786  0.023144  \n",
       "3  0.001467  0.020991  0.027675  0.001621  0.015858  \n",
       "4  0.040599  0.016590  0.032730  0.002498  0.011260  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UMD = pd.read_csv('UMD_TEST.txt', delimiter=\"  \", header=None)\n",
    "UMD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7e79cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isolate the target values\n",
    "y = UMD.pop(0).values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3132d23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.7644459e-02,  3.0949268e-02,  5.0555110e-02,  4.4484418e-02,\n",
       "        5.3276844e-02,  4.1576200e-02,  3.0947384e-02,  2.7085506e-02,\n",
       "        1.3763773e-02,  5.0538801e-03,  4.9583589e-02,  4.7378657e-03,\n",
       "        2.4308760e-02,  2.4478464e-02,  4.3095075e-02,  3.1740094e-02,\n",
       "        3.3707003e-02,  4.4220571e-02,  1.2100000e-01,  4.6200000e-01,\n",
       "        8.1000000e-01,  1.0110000e+00,  1.1070000e+00,  1.1440000e+00,\n",
       "        1.0270000e+00,  6.8500000e-01,  3.4200000e-01,  1.4900000e-01,\n",
       "        5.9000000e-02,  5.5992157e-02,  1.1957117e-02,  1.0609106e-02,\n",
       "        5.3351608e-02,  4.4763044e-02,  2.2176572e-02,  1.3004620e-02,\n",
       "        2.3660634e-02,  2.2580103e-02,  2.4467768e-02,  3.0559437e-02,\n",
       "       -4.9870111e-03,  1.9600643e-02,  3.1117836e-02,  2.3833347e-02,\n",
       "        3.1311257e-02,  3.0431769e-02, -8.4000000e-02, -3.1400000e-01,\n",
       "       -5.3900000e-01, -6.6200000e-01, -7.2100000e-01, -7.5000000e-01,\n",
       "       -7.6400000e-01, -7.6900000e-01, -7.7000000e-01, -7.6800000e-01,\n",
       "       -7.6900000e-01, -7.7300000e-01, -7.7100000e-01, -7.6500000e-01,\n",
       "       -7.6300000e-01, -7.6500000e-01, -7.6700000e-01, -7.6900000e-01,\n",
       "       -7.6800000e-01, -7.6600000e-01, -7.6600000e-01, -7.6700000e-01,\n",
       "       -7.6700000e-01, -7.6500000e-01, -7.6100000e-01, -7.6100000e-01,\n",
       "       -7.6600000e-01, -7.7000000e-01, -7.7000000e-01, -7.6900000e-01,\n",
       "       -7.6800000e-01, -7.6700000e-01, -7.6600000e-01, -7.6600000e-01,\n",
       "       -7.6500000e-01, -7.6300000e-01, -7.6000000e-01, -7.5600000e-01,\n",
       "       -7.5500000e-01, -7.5600000e-01, -7.5500000e-01, -7.5500000e-01,\n",
       "       -7.5600000e-01, -6.7500000e-01, -4.5300000e-01, -2.2700000e-01,\n",
       "       -9.9000000e-02, -1.9824458e-02, -6.3755642e-04,  3.4398935e-02,\n",
       "        4.9393822e-02,  3.4647276e-02,  8.6598457e-03,  3.9904957e-02,\n",
       "        4.3636428e-02,  5.4030599e-02,  3.2503496e-02,  1.5816132e-02,\n",
       "        8.6854844e-03,  4.0595123e-02,  4.3902514e-02,  3.7242898e-04,\n",
       "        1.8474424e-02,  2.2145520e-02,  6.9455943e-04,  8.1170874e-03,\n",
       "        3.6256384e-03,  9.2388105e-04,  3.3231219e-02,  3.5138642e-02,\n",
       "        2.0400030e-02,  1.7797238e-02,  9.8364442e-04,  3.8192065e-02,\n",
       "        1.7391280e-02,  1.7036758e-03,  5.1342677e-03,  7.5542568e-03,\n",
       "        7.2801465e-03,  4.3385256e-02,  3.2223531e-02,  4.3177144e-02,\n",
       "        1.9742928e-02,  3.4348316e-02,  2.8696945e-02,  3.0033275e-02,\n",
       "       -6.7452312e-04,  1.3035638e-02,  3.9789432e-02,  2.3751382e-02,\n",
       "        4.5903242e-02,  4.0239212e-03,  2.2527309e-02,  2.5585360e-02,\n",
       "        2.4574725e-02,  3.3780034e-02,  2.6588896e-02,  1.3932152e-02,\n",
       "        2.4928126e-02,  2.2589026e-02,  3.8248000e-02,  4.9837783e-02,\n",
       "        5.3419439e-02,  4.0420371e-02])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isolate the corresponding features\n",
    "X = UMD.values\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c88de14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96, 150), (48, 150), (96,), (48,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create train and test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d0251dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classifier and fit with training data\n",
    "dtw_classifier = DTWOneNNClassifier()\n",
    "dtw_classifier = dtw_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db8cfd1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166666666666666"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check accuracy with test data\n",
    "acc = dtw_classifier.score(X_test, y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d205db",
   "metadata": {},
   "source": [
    "# Task 1.3 Using Euclidian Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9187c25c",
   "metadata": {},
   "source": [
    "### Comparing with the Euclidian Model\n",
    "Below I will implement the sklearn kNN model using Euclidian distance metrics with 1 nearest neighbour, and compare the performance with my own 1NN DTW classifier. I will then use cross validation with varying number of folds to see the effects on accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40428c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8541666666666666"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_1NN = KNeighborsClassifier(n_neighbors=1)\n",
    "sk_1NN.fit(X_train, y_train)\n",
    "sk_acc = sk_1NN.score(X_test, y_test)\n",
    "sk_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f39c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN = KNeighborsClassifier(n_neighbors=1)  \n",
    "kNN_scores_2cv = cross_val_score(kNN, X, y, cv=2)\n",
    "kNN_scores_4cv = cross_val_score(kNN, X, y, cv=4)\n",
    "kNN_scores_6cv = cross_val_score(kNN, X, y, cv=6)\n",
    "kNN_scores_8cv = cross_val_score(kNN, X, y, cv=8)\n",
    "kNN_scores_10cv = cross_val_score(kNN, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be9fbc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measurement: Custom DTW Function \t\t\tAccuracy: 0.92\n",
      "Measurement: Sklearn 1NN with Euclidian Distance \tAccuracy: 0.85\n",
      "Measurement: 2x CV 1NN with Euclidian Distance \t\tAccuracy: 0.49\n",
      "Measurement: 4x CV 1NN with Euclidian Distance \t\tAccuracy: 0.45\n",
      "Measurement: 6x CV 1NN with Euclidian Distance \t\tAccuracy: 0.84\n",
      "Measurement: 8x CV 1NN with Euclidian Distance \t\tAccuracy: 0.85\n",
      "Measurement: 10x CV 1NN with Euclidian Distance \tAccuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "print('Measurement: Custom DTW Function \\t\\t\\tAccuracy: {0:.2f}'.format(acc))\n",
    "print('Measurement: Sklearn 1NN with Euclidian Distance \\tAccuracy: {0:.2f}'.format(sk_acc))\n",
    "print('Measurement: 2x CV 1NN with Euclidian Distance \\t\\tAccuracy: {0:.2f}'.format(kNN_scores_2cv.mean())) \n",
    "print('Measurement: 4x CV 1NN with Euclidian Distance \\t\\tAccuracy: {0:.2f}'.format(kNN_scores_4cv.mean())) \n",
    "print('Measurement: 6x CV 1NN with Euclidian Distance \\t\\tAccuracy: {0:.2f}'.format(kNN_scores_6cv.mean())) \n",
    "print('Measurement: 8x CV 1NN with Euclidian Distance \\t\\tAccuracy: {0:.2f}'.format(kNN_scores_8cv.mean())) \n",
    "print('Measurement: 10x CV 1NN with Euclidian Distance \\tAccuracy: {0:.2f}'.format(kNN_scores_10cv.mean())) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7203ca03",
   "metadata": {},
   "source": [
    "As seen above, the accuracy using the dtw is superior than when using euclidian distances as a metric, something likely to change even further as the window size of the dtw function is adjusted. When measuring accuracy with k-fold cross validation, we can see that as the fold sizes increase, the accuracy becomes far better, likely due to the size of the test set becoming too small, resulting in overfitting of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6471b56d",
   "metadata": {},
   "source": [
    "# Task 1.4 Best Value for Window Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25e61ee",
   "metadata": {},
   "source": [
    "### Determining Optimum Window Size\n",
    "Below, I experiment with changing window size of the dtw function to see the effect on the accuracy of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5fd24a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new classifier and fit with training data\n",
    "dtw_classifier_windows = DTWOneNNClassifier()\n",
    "dtw_classifier_windows = dtw_classifier_windows.fit(X_train, y_train)\n",
    "window_results = {}\n",
    "\n",
    "for w in range(10):\n",
    "    score = dtw_classifier_windows.score(X_test, y_test, w) \n",
    "    window_results[w] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13d71798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.8541666666666666,\n",
       " 1: 0.8541666666666666,\n",
       " 2: 0.875,\n",
       " 3: 0.9166666666666666,\n",
       " 4: 0.9583333333333334,\n",
       " 5: 0.9791666666666666,\n",
       " 6: 0.9791666666666666,\n",
       " 7: 0.9791666666666666,\n",
       " 8: 0.9791666666666666,\n",
       " 9: 0.9791666666666666}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best window size for set\n",
    "window_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28484194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(window_results.keys(), window_results.values())\n",
    "plt.ylabel(\"Classifier Accuracy\")\n",
    "plt.xlabel(\"Window Size\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146e317b",
   "metadata": {},
   "source": [
    "As we can see from the plot and `window_results` dictionary above, increasing window size increases the accuracy of the classifier until it plateaus at 5. After this point, the accuracy remains constant at 0.979167."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b553af9b",
   "metadata": {},
   "source": [
    "# Task 2.1 Adapting DTW as a Metric Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3145d0bb",
   "metadata": {},
   "source": [
    "### New Metric Function for the sklearn implementation\n",
    "Below, I have altered the dtw function to create `dtw_metric`, a function which can be used in the sklearn implementation of the KNeighborsClassifier, as a metric to calculate distance. The window size has been adjusted to be a kwarg now, with a default value of 3, that can be altered by the metric_params argument of the KNeighborsClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6700d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtw_metric(s, t, **kwargs):\n",
    "\n",
    "    # Check for window size, otherwise default to 3\n",
    "    if \"window\" in kwargs:\n",
    "        window = kwargs[\"window\"]\n",
    "    else:\n",
    "        window = 3\n",
    "        \n",
    "    n, m = len(s), len(t)\n",
    "    w = np.max([window, abs(n-m)]) # warping cannot be less than the difference in lengths. \n",
    "    dtw_matrix = np.zeros((n+1, m+1))\n",
    "    \n",
    "    for i in range(n+1):\n",
    "        for j in range(m+1):\n",
    "            dtw_matrix[i, j] = np.inf\n",
    "    dtw_matrix[0, 0] = 0\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        for j in range(np.max([1, i-w]), np.min([m, i+w])+1):\n",
    "            dtw_matrix[i, j] = 0\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        for j in range(np.max([1, i-w]), np.min([m, i+w])+1):\n",
    "            cost = abs(s[i-1] - t[j-1])\n",
    "            # take last min from a square box\n",
    "            last_min = np.min([dtw_matrix[i-1, j], dtw_matrix[i, j-1], dtw_matrix[i-1, j-1]])\n",
    "            dtw_matrix[i, j] = cost + last_min\n",
    "    return dtw_matrix[-1,-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5b894a",
   "metadata": {},
   "source": [
    "# Task 2.2, 2.3\n",
    "### Comparing Performance of Custom Classifier with Custom Metric Function and Euclidian Distances\n",
    "Below I measure the performance of the Sklearn implementation of the KNeighborsClassifier with my new metric function. I test initially with 1NN and compare with the custom classifier, as expected, the results are the same. Then I experiment with 2 and 3 nearest neighbours of the sklearn implementation, in order to see the effect on the results. Finally, I check the performance of the model using euclidian distance with 2 and 3 nearest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a3b20cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN_custom = KNeighborsClassifier(n_neighbors=1, metric=dtw_metric)\n",
    "kNN_custom = kNN_custom.fit(X_train, y_train)\n",
    "kNN_custom = kNN_custom.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa60ec80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Sklearn KNClassifier with new metric function: \t0.9166666666666666\n",
      "Performance of custom classifier: \t\t\t\t0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "print(f\"Performance of Sklearn KNClassifier with new metric function: \\t{kNN_custom}\")\n",
    "print(f\"Performance of custom classifier: \\t\\t\\t\\t{acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafe7849",
   "metadata": {},
   "source": [
    "As expected, the performance for the classifiers is the same, as they both use the same metrics to make a classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ad1ed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2 and 3 NN classifiers and check accuracy using dtw\n",
    "kNN_custom_2 = KNeighborsClassifier(n_neighbors=2, metric=dtw_metric)\n",
    "kNN_custom_3 = KNeighborsClassifier(n_neighbors=3, metric=dtw_metric)\n",
    "\n",
    "kNN_custom_2 = kNN_custom_2.fit(X_train, y_train)\n",
    "kNN_custom_2_scores = kNN_custom_2.score(X_test, y_test)\n",
    "\n",
    "kNN_custom_3 = kNN_custom_3.fit(X_train, y_train)\n",
    "kNN_custom_3_scores = kNN_custom_3.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6884adea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2 and 3 NN using euclidian distance\n",
    "kNN_euc_2 = KNeighborsClassifier(n_neighbors=2)\n",
    "kNN_euc_3 = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "kNN_euc_2 = kNN_euc_2.fit(X_train, y_train)\n",
    "kNN_euc_2_scores = kNN_euc_2.score(X_test, y_test)\n",
    "\n",
    "kNN_euc_3 = kNN_euc_3.fit(X_train, y_train)\n",
    "kNN_euc_3_scores = kNN_euc_3.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba1c31b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores:\n",
      "2NN with DTW to measure distance: \t\t0.875\n",
      "3NN with DTW to measure distance: \t\t0.8958333333333334\n",
      "2NN with Euclidian to measure distance: \t0.8333333333333334\n",
      "3NN with Euclidian to measure distance: \t0.9375\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy scores:\")\n",
    "print(f\"2NN with DTW to measure distance: \\t\\t{kNN_custom_2_scores}\")\n",
    "print(f\"3NN with DTW to measure distance: \\t\\t{kNN_custom_3_scores}\")\n",
    "print(f\"2NN with Euclidian to measure distance: \\t{kNN_euc_2_scores}\")\n",
    "print(f\"3NN with Euclidian to measure distance: \\t{kNN_euc_3_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98a3b5b",
   "metadata": {},
   "source": [
    "Above we can see the accuracy of the 2 and 3 nearest neighbour classifiers using both euclidian and dtw to distance metrics. As would be expected, dynamic time warping gives a better accuracy for the classifiers than euclidian for the time series data. Similarly, as the number of neighbours increases from 2 to 3, we can see that in the case of both models the accuracy improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffcfd56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
